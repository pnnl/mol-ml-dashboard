{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 12:20:53.553401: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/grac833/opt/anaconda3/envs/mldash/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from data_transformers import SMILESTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select properties of interest\n",
    "loaders = {'solubility_delaney':dc.molnet.load_delaney, 'lipophilicity_lipo': dc.molnet.load_lipo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: solubility_delaney\n",
      "Loading...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grac833/opt/anaconda3/envs/mldash/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "RMSE: 0.43725919024799625, R2: 0.8182304607806024\n",
      "\n",
      "Saving...\n",
      "dataset: lipophilicity_lipo\n",
      "Loading...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grac833/opt/anaconda3/envs/mldash/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "RMSE: 0.656741908331252, R2: 0.4809978242470512\n",
      "\n",
      "Saving...\n"
     ]
    }
   ],
   "source": [
    "#model type to use for prediction\n",
    "model = 'rf'\n",
    "\n",
    "#loop over properties\n",
    "for l, loader in loaders.items():\n",
    "    \n",
    "    print('dataset:',l)\n",
    "    \n",
    "    prop = l.split('_')[0]\n",
    "    dataset = l.split('_')[1]\n",
    "    \n",
    "    print('Loading...')\n",
    "    tasks, datasets, transformers = loader(reload=False)\n",
    "    (train, val, test) = datasets\n",
    "\n",
    "    #scikit learn model\n",
    "    if model == 'rf':\n",
    "        mdl = RandomForestRegressor()    \n",
    "    \n",
    "    \n",
    "    #pipeline to compute descriptors from SMILES and fit a regression model\n",
    "    pipe = Pipeline(steps=[\n",
    "                       ('descriptors', SMILESTransformer()),    \n",
    "                       ('reg', mdl)\n",
    "                ])\n",
    "\n",
    "\n",
    "    #fit model\n",
    "    print('Training...')\n",
    "    pipe.fit(train.ids, train.y)\n",
    "\n",
    "    #predict properties\n",
    "    print('Predicting...')\n",
    "    ytrain_pred = pipe.predict(train.ids)\n",
    "    yval_pred = pipe.predict(val.ids)\n",
    "    ytest_pred = pipe.predict(test.ids)\n",
    "\n",
    "    #create dataframes of SMILES, true values, and predictions\n",
    "    train_df = pd.DataFrame({'SMILES':train.ids,\n",
    "                            'label':train.y.flatten(),\n",
    "                            'pred':ytrain_pred})\n",
    "\n",
    "    val_df = pd.DataFrame({'SMILES':val.ids,\n",
    "                            'label':val.y.flatten(),\n",
    "                            'pred':yval_pred})\n",
    "    test_df = pd.DataFrame({'SMILES':test.ids,\n",
    "                            'label':test.y.flatten(),\n",
    "                            'pred':ytest_pred})\n",
    "\n",
    "    #print metrics\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(test.y, ytest_pred))}, R2: {r2_score(test.y, ytest_pred)}\\n\")\n",
    "    \n",
    "    #create file structure for property data\n",
    "    path = 'property_data'\n",
    "    for dir in ['',prop, dataset, model, 'model']:\n",
    "        path += f'/{dir}'\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    outpath = f'property_data/{prop}/{dataset}/{model}/'\n",
    "        \n",
    "    print('Saving...')\n",
    "    #save data\n",
    "    train_df.to_csv(f'{outpath}/train.csv',index=False)\n",
    "    val_df.to_csv(f'{outpath}/val.csv',index=False)\n",
    "    test_df.to_csv(f'{outpath}/test.csv',index=False)\n",
    "    \n",
    "    #save trained model\n",
    "    joblib.dump(pipe, f'{outpath}/model/{model}_{prop}_model.joblib')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
